# ğŸ‘ï¸â€ğŸ—¨ï¸ Person Detection with Emotion Recognition in Public Spaces Using Google Cloud Vision API ğŸŒ

## ğŸ“ Overview
This project utilizes the Google Vision API and advanced image processing algorithms to detect faces and analyze emotions in images captured by a security camera. The system processes data to provide actionable insights, such as the count of unique individuals and their emotional states. 

![System Architecture](Media/ConceptionArchitecture.png)

---

## ğŸš€ Our Solution
### Key Steps:
- ğŸ“¸ **Image Capture**: A security camera captures real-time images.
- ğŸ–¼ï¸ **Frame Extraction**: Frames are extracted to detect individuals and faces.
- ğŸ˜ƒ **Emotion Analysis**: Faces are analyzed to detect emotions.
- ğŸ”¢ **Unique Person Count**: The system calculates the number of distinct individuals across images.

![Solution Design](Media/ConceptionSolution.png)

---

## ğŸ› ï¸ Software Environment

### ğŸ–¥ï¸ Development Tools
- ğŸ **Anaconda**: For Python environment management and package installation.
- ğŸ““ **Jupyter Notebook**: Interactive code development and documentation.

### ğŸ”§ Technologies Used
- **Python**: Core language for project implementation.
- ğŸ–¼ï¸ **OpenCV (cv2)**: Handles image processing and computer vision tasks.
- ğŸ¤– **Ultralytics YOLO**: Enables real-time object detection.
- ğŸ™‚ **MTCNN**: Detects faces in images.
- ğŸ‘¤ **FaceNetPyTorch**: Extracts facial features for person identification.
- ğŸ§  **DeepFace**: Analyzes facial emotions and ensures facial uniqueness.
- ğŸ“‹ **Google Vision API**: For object recognition, face detection, and OCR.
- ğŸ§® Libraries like **numpy** and **shutil** for numerical operations and file management.

---

## ğŸ” Development Details

### ğŸ”— System Integration
During development, the system was connected to a surveillance camera to:
1. ğŸ¥ Capture real-time video streams and extract frames.
2. ğŸ› ï¸ Detect individuals and analyze their emotions.
3. ğŸ§® Count unique individuals across multiple frames.

### ğŸ§© Key Processes
#### 1ï¸âƒ£ Frame Extraction from Camera
Captures and crops images from the camera's region of interest (ROI), ensuring only valid and non-empty frames are saved.

**File:** `extract.py`

#### 2ï¸âƒ£ Using Google Cloud Vision API
Processes images to detect people and their emotions, saving results with filenames indicating the dominant emotion.

**File:** `GoocglecloudAPI.py`

#### 3ï¸âƒ£ Emotion Detection and Person Counting
- **Face Detection and Emotion Analysis:** YOLO and MTCNN detect faces, while DeepFace analyzes emotions.
  - **File:** `FaceDetectionemotion.py`
- **Unique Person Counting:** MTCNN and InceptionResnetV1 identify unique individuals by comparing facial embeddings.
  - **File:** `estmatinguniquepeoplecount.py`

---

## ğŸ“Š Testing and Validation
Our solution showed improved performance compared to the Google Vision API in specific tests, demonstrating robustness under various conditions.

![Test Results](Media/Tests.png)

---

## ğŸ“‚ File Structure
- ğŸ“ **`Media/ConceptionArchitecture.png`**: System architecture diagram.
- ğŸ“ **`Media/ConceptionSolution.png`**: Solution design illustration.
- ğŸ“ **`Media/Tests.png`**: Test and validation results.
- ğŸ“„ **`extract.py`**: Script for extracting frames from the camera.
- ğŸ“„ **`GoocglecloudAPI.py`**: Script utilizing the Google Cloud Vision API.
- ğŸ“„ **`FaceDetectionemotion.py`**: Script for face detection and emotion analysis.
- ğŸ“„ **`estmatinguniquepeoplecount.py`**: Script for counting unique individuals.

---

